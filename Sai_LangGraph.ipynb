{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffdff364-8035-4546-94c5-fd64ad026391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (0.3.28)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.3.69)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.97.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.13.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.11.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langgraph\n",
      "  Downloading langgraph-0.5.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.69)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langgraph-prebuilt<0.6.0,>=0.5.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.73-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.4)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.18)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Downloading langgraph-0.5.3-py3-none-any.whl (143 kB)\n",
      "Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n",
      "Downloading langgraph_prebuilt-0.5.2-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.73-py3-none-any.whl (50 kB)\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
      "Installing collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [langgraph]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langgraph-0.5.3 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.5.2 langgraph-sdk-0.1.73 ormsgpack-1.10.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai\n",
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bbb88-b0e3-4596-b9d7-f8ccf8e69437",
   "metadata": {},
   "source": [
    "## Setting up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a28348e2-63ad-41f7-9348-dc4ae833199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model=\"Qwen/Qwen3-4B\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    base_url=\"http://localhost:4000/v1/\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59979e81-12dc-4e89-8eb4-d8bdcc6fb841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user said \"hi\". I need to respond appropriately. Since they just greeted me, I should acknowledge their greeting. Maybe say hello back and offer assistance. Keep it friendly and open-ended. Let them know I\\'m here to help with anything they need. Make sure the response is concise but welcoming. Avoid any technical jargon. Just a simple, warm reply.\\n</think>\\n\\nHello! How can I assist you today? 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 9, 'total_tokens': 101, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-4B', 'system_fingerprint': None, 'id': 'chatcmpl-845b7ba1667b4c53939127eab2e97b3c', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--edfa1ac7-e47a-44fd-a576-f81abdd0d4df-0', usage_metadata={'input_tokens': 9, 'output_tokens': 92, 'total_tokens': 101, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d62d29-29a3-4c19-a6d2-73b18c709f27",
   "metadata": {},
   "source": [
    "## Set up LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a74cdc11-89a1-4b19-9d70-479b6db8bc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Address already in use\n",
      "Port 5002 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List, Annotated\n",
    "import operator\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import necessary Google API client libraries - assuming they are installed\n",
    "try:\n",
    "    from google.oauth2.credentials import Credentials\n",
    "    from googleapiclient.discovery import build\n",
    "except ImportError:\n",
    "    print(\"Google API client libraries not found. Calendar event retrieval will not function.\")\n",
    "    Credentials = None\n",
    "    build = None\n",
    "\n",
    "# --- 1. Define the State of your Agent ---\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our agent in the graph.\n",
    "    \"\"\"\n",
    "    request_id: str\n",
    "    datetime_of_request: str\n",
    "    sender_email: str\n",
    "    attendees_emails: List[str]\n",
    "    subject: str\n",
    "    email_content: str\n",
    "    calendar_events: List[dict]  # To store fetched calendar events for all attendees\n",
    "    event_start: str\n",
    "    event_end: str\n",
    "    duration_mins: str\n",
    "    metadata: dict\n",
    "    intermediate_steps: List[str] # To log thought process or actions\n",
    "    tool_output: str # Output from tools\n",
    "    llm_response: str # Final response from LLM or intermediate LLM thoughts\n",
    "    # Added for the new meeting event details if scheduled\n",
    "    scheduled_event_summary: str\n",
    "    scheduled_event_attendees: List[str]\n",
    "    location: str # Added location to AgentState\n",
    "\n",
    "\n",
    "# --- 2. Define Tools (Functions the AI Agent can use) ---\n",
    "\n",
    "# Provided Google Calendar Event Fetcher code\n",
    "def retrive_calendar_events(user, start, end):\n",
    "    events_list = []\n",
    "    if Credentials and build:\n",
    "        try:\n",
    "            token_path = \"Keys/\"+user.split(\"@\")[0]+\".token\"\n",
    "            user_creds = Credentials.from_authorized_user_file(token_path)\n",
    "            calendar_service = build(\"calendar\", \"v3\", credentials=user_creds)\n",
    "            events_result = calendar_service.events().list(calendarId='primary', timeMin=start,timeMax=end,singleEvents=True,orderBy='startTime').execute()\n",
    "            events = events_result.get('items')\n",
    "\n",
    "            for event in events :\n",
    "                attendee_list = []\n",
    "                try:\n",
    "                    for attendee in event[\"attendees\"]:\n",
    "                        attendee_list.append(attendee['email'])\n",
    "                except:\n",
    "                    attendee_list.append(\"SELF\")\n",
    "                try:\n",
    "                    start_time = event[\"start\"][\"dateTime\"]\n",
    "                    end_time = event[\"end\"][\"dateTime\"]\n",
    "                    events_list.append(\n",
    "                        {\"StartTime\" : start_time,\n",
    "                         \"EndTime\": end_time,\n",
    "                         \"NumAttendees\" :len(set(attendee_list)),\n",
    "                         \"Attendees\" : list(set(attendee_list)),\n",
    "                         \"Summary\" : event[\"summary\"]})\n",
    "                except Exception as E:\n",
    "                    print(f'Exception processing event: {E}')\n",
    "            print(f'Retrieved {len(events_list)} events for {user}')\n",
    "            return events_list\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Could not retrieve calendar events for {user} due to: {e}. Ensure token file exists and is valid.\")\n",
    "            return []\n",
    "    else:\n",
    "        print(\"DEBUG: Google API client libraries not available. Cannot call retrive_calendar_events.\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Tool 1: Google Calendar Event Fetcher\n",
    "def fetch_calendar_events_tool(attendee_email: str, start_date_str: str, end_date_str: str) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Fetches calendar events for a given attendee within a date range using the provided retrieval function.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: Calling fetch_calendar_events_tool for {attendee_email} from {start_date_str} to {end_date_str}\")\n",
    "    \n",
    "    # Use the actual retrieval function directly\n",
    "    retrieved_events = retrive_calendar_events(attendee_email, start_date_str, end_date_str)\n",
    "    \n",
    "    # Deduplicate events based on start, end, summary, and attendees\n",
    "    unique_events = []\n",
    "    seen = set()\n",
    "    for event in retrieved_events:\n",
    "        # Create a hashable tuple from event details to check for duplicates\n",
    "        # Convert list of attendees to sorted tuple to ensure consistent hashing regardless of order\n",
    "        event_tuple = (event.get('StartTime'), event.get('EndTime'), event.get('Summary'), tuple(sorted(event.get('Attendees', []))))\n",
    "        if event_tuple not in seen:\n",
    "            unique_events.append(event)\n",
    "            seen.add(event_tuple)\n",
    "\n",
    "    return unique_events\n",
    "\n",
    "\n",
    "# Tool 2: Meeting Scheduler (Hypothetical - this would interact with Google Calendar API to create an event)\n",
    "def schedule_meeting_tool(summary: str, start_time: str, end_time: str, attendees: List[str], location: str = \"\") -> dict:\n",
    "    \"\"\"\n",
    "    Schedules a meeting in Google Calendar.\n",
    "    This would be an API call to create a new calendar event.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: Calling schedule_meeting_tool for {summary} at {start_time} to {end_time} with {attendees}\")\n",
    "    # In a real scenario, this would interact with Google Calendar API to create an event.\n",
    "    # For now, just print and return a success message.\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"message\": f\"Meeting '{summary}' scheduled from {start_time} to {end_time}.\",\n",
    "        \"scheduled_event_details\": {\n",
    "            \"StartTime\": start_time,\n",
    "            \"EndTime\": end_time,\n",
    "            \"NumAttendees\": len(attendees),\n",
    "            \"Attendees\": attendees,\n",
    "            \"Summary\": summary\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Tool 3: Conflict Resolver / Rescheduler (Hypothetical)\n",
    "def resolve_conflict_tool(meeting_summary: str, conflicted_time: str, alternative_times: List[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Attempts to reschedule a meeting to resolve conflicts.\n",
    "    This would involve checking alternative_times and updating the calendar.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: Resolving conflict for {meeting_summary} at {conflicted_time} with alternatives: {alternative_times}\")\n",
    "    # Logic to find the first available alternative and update.\n",
    "    # For this example, we'll just pick the first alternative\n",
    "    if alternative_times:\n",
    "        new_time = alternative_times[0]\n",
    "        return {\"status\": \"resolved\", \"new_time\": new_time, \"message\": f\"Meeting rescheduled to {new_time}\"}\n",
    "    return {\"status\": \"failed\", \"message\": \"No alternative times provided.\"}\n",
    "\n",
    "\n",
    "# --- 3. Define the LLM Interaction ---\n",
    "def call_llm(state: AgentState) -> dict:\n",
    "    \"\"\"\n",
    "    Calls the vLLM server with the Qwen 30B model to get a response.\n",
    "    The prompt engineering here is crucial for agentic behavior.\n",
    "    \"\"\"\n",
    "    print(\"DEBUG: Calling LLM for reasoning and action selection...\")\n",
    "\n",
    "    # Construct the prompt based on the current state\n",
    "    # This is where you engineer your prompt to encourage reasoning, tool use, and structured output.\n",
    "    # The prompt should guide the LLM to identify intent, extract entities, and decide on actions.\n",
    "\n",
    "    # Format current calendar events for LLM\n",
    "    formatted_calendar_events = []\n",
    "    if state['calendar_events']:\n",
    "        for event in state['calendar_events']:\n",
    "            formatted_calendar_events.append(f\"- Summary: {event.get('Summary', 'N/A')}, Start: {event.get('StartTime', 'N/A')}, End: {event.get('EndTime', 'N/A')}, Attendees: {', '.join(event.get('Attendees', []))}\")\n",
    "    \n",
    "    calendar_info = \"\\nExisting Calendar Events (if any, for all attendees):\\n\" + \"\\n\".join(formatted_calendar_events) if formatted_calendar_events else \"\\nExisting Calendar Events: None.\"\n",
    "\n",
    "    prompt = f\"\"\"You are an intelligent AI scheduling assistant. Your goal is to autonomously schedule, reschedule, and optimize meetings.\n",
    "    \n",
    "Here is the current meeting request:\n",
    "Request ID: {state['request_id']}\n",
    "From: {state['sender_email']}\n",
    "Attendees: {', '.join(state['attendees_emails'])}\n",
    "Subject: {state['subject']}\n",
    "Content: {state['email_content']}\n",
    "{calendar_info}\n",
    "\n",
    "You need to decide the next best action.\n",
    "Based on the email content, determine the meeting's purpose, desired duration, and any time preferences (e.g., \"Thursday\").\n",
    "If you need to fetch calendar availability, use the 'fetch_calendar_events_tool'. Always fetch calendar events for ALL attendees mentioned in the request and also the sender's calendar.\n",
    "If you have identified a suitable time, use the 'schedule_meeting_tool'. Ensure the scheduled time avoids conflicts with existing 'calendar_events'. If a conflict exists, propose an alternative time within the next few days.\n",
    "If there are conflicts and an alternative is suggested, use 'resolve_conflict_tool'.\n",
    "\n",
    "Your output should be a JSON object with an 'action' key and 'arguments' key.\n",
    "Possible actions: \"fetch_calendar_events\", \"schedule_meeting\", \"resolve_conflict\", \"final_answer\".\n",
    "\n",
    "Example for fetching calendar events:\n",
    "{{\n",
    "    \"action\": \"fetch_calendar_events\",\n",
    "    \"arguments\": {{\n",
    "        \"attendee_email\": \"user@example.com\",\n",
    "        \"start_date\": \"YYYY-MM-DD\",\n",
    "        \"end_date\": \"YYYY-MM-DD\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Example for scheduling a meeting:\n",
    "{{\n",
    "    \"action\": \"schedule_meeting\",\n",
    "    \"arguments\": {{\n",
    "        \"summary\": \"Meeting Title\",\n",
    "        \"start_time\": \"YYYY-MM-DDTHH:MM:SS+05:30\",\n",
    "        \"end_time\": \"YYYY-MM-DDTHH:MM:SS+05:30\",\n",
    "        \"attendees\": [\"email1@example.com\", \"email2@example.com\"],\n",
    "        \"location\": \"Optional Location\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Example for resolving a conflict:\n",
    "{{\n",
    "    \"action\": \"resolve_conflict\",\n",
    "    \"arguments\": {{\n",
    "        \"meeting_summary\": \"Original Meeting Title\",\n",
    "        \"conflicted_time\": \"YYYY-MM-DDTHH:MM:SS+05:30\",\n",
    "        \"alternative_times\": [\"YYYY-MM-DDTHH:MM:SS+05:30\", \"YYYY-MM-DDTHH:MM:SS+05:30\"]\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Example for final answer (when meeting is scheduled or confirmed and you have all details):\n",
    "{{\n",
    "    \"action\": \"final_answer\",\n",
    "    \"arguments\": {{\n",
    "        \"event_start\": \"YYYY-MM-DDTHH:MM:SS+05:30\",\n",
    "        \"event_end\": \"YYYY-MM-DDTHH:MM:SS+05:30\",\n",
    "        \"duration_mins\": \"30\",\n",
    "        \"summary\": \"Agentic AI Project Status Update\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Consider the current date as {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}.\n",
    "If the email mentions \"Thursday\", assume it refers to the upcoming Thursday from the current date.\n",
    "If the email mentions a duration (e.g., \"30 minutes\"), use that for the meeting.\n",
    "What is your next action?\n",
    "\"\"\"\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    # Adjust this URL to your vLLM server endpoint\n",
    "    vllm_url = \"http://localhost:3000/generate\" #\n",
    "    \n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 500,  # Adjust as needed\n",
    "        \"temperature\": 0.1,\n",
    "        \"stop\": [\"}}\", \"```\"] # Adjust stop tokens if your LLM output format is different\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(vllm_url, headers=headers, json=payload, timeout=8) # 8-second timeout for LLM\n",
    "        response.raise_for_status()\n",
    "        llm_output = response.json()[\"text\"][0].strip()\n",
    "        print(f\"DEBUG: LLM Raw Output: {llm_output}\")\n",
    "\n",
    "        # Attempt to parse the LLM's JSON output\n",
    "        json_start = llm_output.find('{')\n",
    "        json_end = llm_output.rfind('}')\n",
    "        if json_start != -1 and json_end != -1:\n",
    "            json_str = llm_output[json_start : json_end + 1]\n",
    "            llm_decision = json.loads(json_str)\n",
    "        else:\n",
    "            raise ValueError(\"LLM output is not a valid JSON structure.\")\n",
    "\n",
    "        return {\"llm_response\": llm_output, \"llm_decision\": llm_decision}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling vLLM server: {e}\")\n",
    "        return {\"llm_response\": f\"Error: {e}\", \"llm_decision\": {\"action\": \"error\"}}\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing LLM response JSON: {e}\")\n",
    "        return {\"llm_response\": f\"Error parsing JSON: {e}\", \"llm_decision\": {\"action\": \"error\"}}\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {\"llm_response\": f\"Error: {e}\", \"llm_decision\": {\"action\": \"error\"}}\n",
    "\n",
    "\n",
    "# --- 4. Define Agent Nodes (Actions) ---\n",
    "\n",
    "def tool_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Executes the tool chosen by the LLM.\n",
    "    \"\"\"\n",
    "    llm_decision = state.get(\"llm_decision\")\n",
    "    action = llm_decision.get(\"action\")\n",
    "    arguments = llm_decision.get(\"arguments\", {})\n",
    "    tool_output = None\n",
    "    \n",
    "    updated_state = {}\n",
    "\n",
    "    if action == \"fetch_calendar_events\":\n",
    "        all_attendee_emails = list(set(state['attendees_emails'] + [state['sender_email']])) # Include sender\n",
    "        all_attendee_events = []\n",
    "        today = datetime.now()\n",
    "        end_date = today + timedelta(days=14) # Fetch for the next 14 days to give more scheduling flexibility\n",
    "        \n",
    "        for email in all_attendee_emails:\n",
    "            # Note: retrive_calendar_events expects datetime strings, not just dates.\n",
    "            # Using ISO format with UTC offset for start and end times to be safe.\n",
    "            # For simplicity, we'll use start of day and end of day for the range.\n",
    "            start_of_day = datetime(today.year, today.month, today.day, 0, 0, 0)\n",
    "            end_of_day = datetime(end_date.year, end_date.month, end_date.day, 23, 59, 59)\n",
    "            \n",
    "            # This is a placeholder for actual timezone handling if needed.\n",
    "            # Google Calendar API often prefers 'Z' for UTC or a specific offset.\n",
    "            # Assuming current time is in +05:30 (IST) as per the overall context.\n",
    "            # For `timeMin` and `timeMax` in Calendar API, a simple ISO format might suffice,\n",
    "            # but providing timezone info is best.\n",
    "            # Example: 2025-07-19T00:00:00+05:30\n",
    "            start_date_formatted = start_of_day.isoformat(timespec='seconds') + '+05:30' # Assuming IST offset\n",
    "            end_date_formatted = end_of_day.isoformat(timespec='seconds') + '+05:30' # Assuming IST offset\n",
    "\n",
    "            events_for_email = fetch_calendar_events_tool(email, start_date_formatted, end_date_formatted)\n",
    "            all_attendee_events.extend(events_for_email)\n",
    "\n",
    "        # Merge new events with existing ones in the state, avoid duplicates\n",
    "        current_events = state.get('calendar_events', [])\n",
    "        for new_event in all_attendee_events:\n",
    "            is_duplicate = False\n",
    "            for existing_event in current_events:\n",
    "                if (existing_event.get('StartTime') == new_event.get('StartTime') and\n",
    "                    existing_event.get('EndTime') == new_event.get('EndTime') and\n",
    "                    existing_event.get('Summary') == new_event.get('Summary') and\n",
    "                    sorted(existing_event.get('Attendees', [])) == sorted(new_event.get('Attendees', []))):\n",
    "                    is_duplicate = True\n",
    "                    break\n",
    "            if not is_duplicate:\n",
    "                current_events.append(new_event)\n",
    "        \n",
    "        tool_output = f\"Fetched calendar events: {len(all_attendee_events)} events found.\"\n",
    "        updated_state[\"calendar_events\"] = current_events\n",
    "        updated_state[\"tool_output\"] = tool_output\n",
    "        return updated_state\n",
    "\n",
    "    elif action == \"schedule_meeting\":\n",
    "        schedule_result = schedule_meeting_tool(\n",
    "            summary=arguments.get(\"summary\"),\n",
    "            start_time=arguments.get(\"start_time\"),\n",
    "            end_time=arguments.get(\"end_time\"),\n",
    "            attendees=arguments.get(\"attendees\"),\n",
    "            location=arguments.get(\"location\", state.get('location', \"IISc Bangalore\")) # Use location from state or default\n",
    "        )\n",
    "        \n",
    "        updated_state[\"tool_output\"] = json.dumps(schedule_result)\n",
    "        \n",
    "        # Update state with scheduled event details for final output formatting\n",
    "        if schedule_result.get(\"status\") == \"success\" and schedule_result.get(\"scheduled_event_details\"):\n",
    "            scheduled_details = schedule_result[\"scheduled_event_details\"]\n",
    "            updated_state[\"event_start\"] = scheduled_details.get(\"StartTime\", \"\")\n",
    "            updated_state[\"event_end\"] = scheduled_details.get(\"EndTime\", \"\")\n",
    "            \n",
    "            try:\n",
    "                # Ensure correct parsing for duration calculation, handle potential missing timezone\n",
    "                start_time_str = scheduled_details[\"StartTime\"]\n",
    "                end_time_str = scheduled_details[\"EndTime\"]\n",
    "\n",
    "                # Add a dummy timezone if not present, for parsing\n",
    "                if len(start_time_str) == 19 and start_time_str.endswith('T'): # YYYY-MM-DDTHH:MM:SS\n",
    "                    start_dt = datetime.fromisoformat(start_time_str + '+00:00') # Assume UTC if no TZ\n",
    "                elif len(start_time_str) > 19 and (start_time_str[-6] == '+' or start_time_str[-6] == '-'): # YYYY-MM-DDTHH:MM:SS+HH:MM\n",
    "                    start_dt = datetime.fromisoformat(start_time_str)\n",
    "                else: # Fallback for other formats, try parsing directly\n",
    "                    start_dt = datetime.fromisoformat(start_time_str.replace('Z', '+00:00')) # Replace Z with UTC offset\n",
    "                \n",
    "                if len(end_time_str) == 19 and end_time_str.endswith('T'):\n",
    "                    end_dt = datetime.fromisoformat(end_time_str + '+00:00')\n",
    "                elif len(end_time_str) > 19 and (end_time_str[-6] == '+' or end_time_str[-6] == '-'):\n",
    "                    end_dt = datetime.fromisoformat(end_time_str)\n",
    "                else:\n",
    "                    end_dt = datetime.fromisoformat(end_time_str.replace('Z', '+00:00'))\n",
    "\n",
    "\n",
    "                updated_state[\"duration_mins\"] = str(int((end_dt - start_dt).total_seconds() / 60))\n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: Could not parse start/end times for duration calculation: {scheduled_details.get('StartTime')}, {scheduled_details.get('EndTime')} Error: {e}\")\n",
    "                updated_state[\"duration_mins\"] = \"0\" # Default or placeholder\n",
    "            \n",
    "            updated_state[\"scheduled_event_summary\"] = scheduled_details.get(\"Summary\", \"\")\n",
    "            updated_state[\"scheduled_event_attendees\"] = scheduled_details.get(\"Attendees\", [])\n",
    "            \n",
    "            # Add the newly scheduled event to calendar_events for the output formatting node\n",
    "            current_events = state.get('calendar_events', [])\n",
    "            current_events.append(scheduled_details)\n",
    "            updated_state[\"calendar_events\"] = current_events\n",
    "\n",
    "        return updated_state\n",
    "\n",
    "    elif action == \"resolve_conflict\":\n",
    "        resolve_result = resolve_conflict_tool(\n",
    "            meeting_summary=arguments.get(\"meeting_summary\"),\n",
    "            conflicted_time=arguments.get(\"conflicted_time\"),\n",
    "            alternative_times=arguments.get(\"alternative_times\")\n",
    "        )\n",
    "        updated_state[\"tool_output\"] = json.dumps(resolve_result)\n",
    "        # If successfully resolved, the LLM should then proceed to schedule_meeting again\n",
    "        return updated_state\n",
    "    \n",
    "    elif action == \"error\":\n",
    "        print(f\"Error action triggered: {state.get('llm_response')}\")\n",
    "        return {\"tool_output\": state.get('llm_response')}\n",
    "\n",
    "    else:\n",
    "        tool_output = f\"No valid tool action specified by LLM or action: {action} is not supported. LLM Response: {state.get('llm_response')}\"\n",
    "        print(tool_output)\n",
    "        return {\"tool_output\": tool_output}\n",
    "\n",
    "def format_final_output_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Formats the final output as per the specified JSON structure for submission.\n",
    "    \"\"\"\n",
    "    print(\"DEBUG: Formatting final output...\")\n",
    "    \n",
    "    # Consolidate all relevant attendees, including the sender\n",
    "    all_involved_emails = list(set(state['attendees_emails'] + [state['sender_email']]))\n",
    "    \n",
    "    output_attendees = []\n",
    "    \n",
    "    # Iterate through all involved emails to gather their events\n",
    "    for email in all_involved_emails:\n",
    "        attendee_data = {\"email\": email, \"events\": []}\n",
    "        \n",
    "        # Add events from the 'calendar_events' list that involve this attendee\n",
    "        for event in state['calendar_events']:\n",
    "            # Check if the attendee's email is explicitly in the event's attendees list\n",
    "            # Or if 'SELF' is used and it's the sender's email\n",
    "            if email in event.get('Attendees', []) or (\"SELF\" in event.get('Attendees', []) and email == state['sender_email']):\n",
    "                 # Ensure the event structure matches the expected output\n",
    "                formatted_event = {\n",
    "                    \"StartTime\": event.get(\"StartTime\", \"\"),\n",
    "                    \"EndTime\": event.get(\"EndTime\", \"\"),\n",
    "                    \"NumAttendees\": event.get(\"NumAttendees\", 0),\n",
    "                    \"Attendees\": event.get(\"Attendees\", []),\n",
    "                    \"Summary\": event.get(\"Summary\", \"\")\n",
    "                }\n",
    "                # Avoid adding exact duplicate events within a single attendee's list\n",
    "                if formatted_event not in attendee_data[\"events\"]:\n",
    "                    attendee_data[\"events\"].append(formatted_event)\n",
    "        output_attendees.append(attendee_data)\n",
    "\n",
    "    output = {\n",
    "        \"Request_id\": state['request_id'],\n",
    "        \"Datetime\": state['datetime_of_request'],\n",
    "        \"Location\": state.get('location', \"IISc Bangalore\"), # Use location from state or default\n",
    "        \"From\": state['sender_email'],\n",
    "        \"Attendees\": output_attendees, # Updated attendees structure\n",
    "        \"Subject\": state['subject'], # Use original subject, or scheduled_event_summary if LLM refined\n",
    "        \"EmailContent\": state['email_content'],\n",
    "        \"EventStart\": state.get('event_start', \"\"),\n",
    "        \"EventEnd\": state.get('event_end', \"\"),\n",
    "        \"Duration_mins\": state.get('duration_mins', \"\"),\n",
    "        \"MetaData\": state.get('metadata', {}) # Should typically be an empty dict or specific metadata\n",
    "    }\n",
    "\n",
    "    return {\"final_output\": output}\n",
    "\n",
    "\n",
    "# --- 5. Define Conditional Edges (Routing Logic) ---\n",
    "\n",
    "def decide_next_step(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Determines the next step in the graph based on the LLM's decision.\n",
    "    \"\"\"\n",
    "    llm_decision = state.get(\"llm_decision\")\n",
    "    if not llm_decision:\n",
    "        print(\"DECISION: No LLM decision found, stopping.\")\n",
    "        return \"end\" # Or transition to an error handling node\n",
    "\n",
    "    action = llm_decision.get(\"action\")\n",
    "\n",
    "    if action == \"fetch_calendar_events\":\n",
    "        print(\"DECISION: LLM decided to fetch calendar events.\")\n",
    "        return \"call_tool\"\n",
    "    elif action == \"schedule_meeting\":\n",
    "        print(\"DECISION: LLM decided to schedule meeting.\")\n",
    "        return \"call_tool\"\n",
    "    elif action == \"resolve_conflict\":\n",
    "        print(\"DECISION: LLM decided to resolve conflict.\")\n",
    "        return \"call_tool\"\n",
    "    elif action == \"final_answer\":\n",
    "        print(\"DECISION: LLM provided final answer.\")\n",
    "        return \"format_output\"\n",
    "    elif action == \"error\":\n",
    "        print(\"DECISION: LLM indicated an error or invalid action.\")\n",
    "        return \"format_output\" # Can also route to a specific error handling node\n",
    "    else:\n",
    "        print(f\"DECISION: Unknown action: {action}. Re-calling LLM.\")\n",
    "        return \"call_llm\" # Loop back to LLM if decision is unclear or invalid\n",
    "\n",
    "\n",
    "# --- 6. Build the LangGraph ---\n",
    "\n",
    "def create_scheduling_agent_graph():\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    workflow.add_node(\"call_llm\", call_llm)\n",
    "    workflow.add_node(\"call_tool\", tool_node)\n",
    "    workflow.add_node(\"format_output\", format_final_output_node)\n",
    "\n",
    "    # Set the entry point\n",
    "    workflow.set_entry_point(\"call_llm\")\n",
    "\n",
    "    # Define edges (transitions)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"call_llm\",  # From call_llm node\n",
    "        decide_next_step, # Use decide_next_step function to determine next node\n",
    "        {\n",
    "            \"call_tool\": \"call_tool\",\n",
    "            \"format_output\": \"format_output\",\n",
    "            \"end\": END # If LLM decides it's done or an error occurs\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # After a tool call, always go back to the LLM for further reasoning/action\n",
    "    workflow.add_edge(\"call_tool\", \"call_llm\")\n",
    "\n",
    "    # After formatting the output, the process ends\n",
    "    workflow.add_edge(\"format_output\", END)\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "# Instantiate the graph\n",
    "scheduling_agent_graph = create_scheduling_agent_graph()\n",
    "\n",
    "\n",
    "# --- 7. Integrate with your `your_meeting_assistant` function ---\n",
    "\n",
    "def your_meeting_assistant(data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Main function to be called by the Flask server.\n",
    "    Initializes the agent state and runs the LangGraph.\n",
    "    \"\"\"\n",
    "    # Initialize the state based on the input request JSON\n",
    "    initial_state = AgentState(\n",
    "        request_id=data.get(\"Request_id\", \"\"),\n",
    "        datetime_of_request=data.get(\"Datetime\", \"\"),\n",
    "        sender_email=data.get(\"From\", \"\"),\n",
    "        attendees_emails=[att[\"email\"] for att in data.get(\"Attendees\", [])],\n",
    "        subject=data.get(\"Subject\", \"\"),\n",
    "        email_content=data.get(\"EmailContent\", \"\"),\n",
    "        location=data.get(\"Location\", \"IISc Bangalore\"), # Initialize location\n",
    "        calendar_events=[],  # Will be populated by the agent\n",
    "        event_start=\"\",\n",
    "        event_end=\"\",\n",
    "        duration_mins=\"\",\n",
    "        metadata=data.get(\"MetaData\", {}), # Initialize with any metadata from input\n",
    "        intermediate_steps=[],\n",
    "        tool_output=\"\",\n",
    "        llm_response=\"\",\n",
    "        scheduled_event_summary=\"\",\n",
    "        scheduled_event_attendees=[]\n",
    "    )\n",
    "\n",
    "    # Run the graph\n",
    "    final_state = None\n",
    "    for s in scheduling_agent_graph.stream(initial_state, {\"recursion_limit\": 50}): # Limit recursion to prevent infinite loops\n",
    "        # print(s) # Uncomment for debugging to see intermediate states\n",
    "        final_state = s\n",
    "\n",
    "    # Extract the final output from the last state\n",
    "    if final_state and 'format_output' in final_state:\n",
    "        return final_state['format_output']['final_output']\n",
    "    elif final_state and 'llm_decision' in final_state and final_state['llm_decision'].get('action') == 'final_answer':\n",
    "         # If LLM directly returned a final answer without going through format_output_node\n",
    "        llm_args = final_state['llm_decision'].get('arguments', {})\n",
    "        # This path might not generate the full 'events' list per attendee,\n",
    "        # so it's best to always route through `format_final_output_node` for consistency.\n",
    "        # However, for robustness, we'll try to construct a basic one if this path is hit.\n",
    "        \n",
    "        # Manually construct simplified output for this direct LLM path\n",
    "        output_attendees_simplified = []\n",
    "        all_involved_emails = list(set(initial_state['attendees_emails'] + [initial_state['sender_email']]))\n",
    "        for email in all_involved_emails:\n",
    "            output_attendees_simplified.append({\"email\": email, \"events\": []}) # Events might be empty here\n",
    "        \n",
    "        output_from_llm_direct = {\n",
    "            \"Request_id\": initial_state['request_id'],\n",
    "            \"Datetime\": initial_state['datetime_of_request'],\n",
    "            \"Location\": initial_state.get('location', \"IISc Bangalore\"),\n",
    "            \"From\": initial_state['sender_email'],\n",
    "            \"Attendees\": output_attendees_simplified, # Simplified attendees\n",
    "            \"Subject\": llm_args.get(\"summary\", initial_state['subject']),\n",
    "            \"EmailContent\": initial_state['email_content'],\n",
    "            \"EventStart\": llm_args.get(\"event_start\", \"\"),\n",
    "            \"EventEnd\": llm_args.get(\"event_end\", \"\"),\n",
    "            \"Duration_mins\": llm_args.get(\"duration_mins\", \"\"),\n",
    "            \"MetaData\": initial_state.get('metadata', {})\n",
    "        }\n",
    "        return output_from_llm_direct\n",
    "    else:\n",
    "        print(\"ERROR: Graph did not produce a final formatted output.\")\n",
    "        # Return a default or error output format\n",
    "        output_attendees_error = []\n",
    "        all_involved_emails = list(set(initial_state['attendees_emails'] + [initial_state['sender_email']]))\n",
    "        for email in all_involved_emails:\n",
    "            output_attendees_error.append({\"email\": email, \"events\": []})\n",
    "\n",
    "        return {\n",
    "            \"Request_id\": initial_state['request_id'],\n",
    "            \"Datetime\": initial_state['datetime_of_request'],\n",
    "            \"Location\": initial_state.get('location', \"IISc Bangalore\"),\n",
    "            \"From\": initial_state['sender_email'],\n",
    "            \"Attendees\": output_attendees_error,\n",
    "            \"Subject\": initial_state['subject'],\n",
    "            \"EmailContent\": initial_state['email_content'],\n",
    "            \"EventStart\": \"\",\n",
    "            \"EventEnd\": \"\",\n",
    "            \"Duration_mins\": \"\",\n",
    "            \"MetaData\": {\"error\": \"Could not schedule meeting or format output. Check LLM logs.\"}\n",
    "        }\n",
    "\n",
    "# --- Flask Server Integration (from your provided notebook) ---\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from threading import Thread\n",
    "\n",
    "app = Flask(__name__)\n",
    "received_data = []\n",
    "\n",
    "@app.route('/receive', methods=['POST'])\n",
    "def receive():\n",
    "    data = request.get_json()\n",
    "    print(f\"\\nReceived: {json.dumps(data, indent=2)}\")\n",
    "    new_data = your_meeting_assistant(data) # Your AI Meeting Assistant Function Call\n",
    "    received_data.append(data)\n",
    "    print(f\"\\nSending: {json.dumps(new_data, indent=2)}\")\n",
    "    return jsonify(new_data)\n",
    "\n",
    "def run_flask():\n",
    "    app.run(host='129.212.190.146', port=5002)\n",
    "\n",
    "# Start Flask in a background thread\n",
    "Thread(target=run_flask, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92183099-e722-40cf-841c-8e7c87dba2da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
