{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb40a4-12bd-4d0d-94d7-e28e8e249bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIP_VISIBLE_DEVICES=0 vllm serve Qwen/Qwen3-4B \\\n",
    "        --gpu-memory-utilization 0.3 \\\n",
    "        --swap-space 16 \\\n",
    "        --disable-log-requests \\\n",
    "        --dtype float16 \\\n",
    "        --max-model-len 2048 \\\n",
    "        --tensor-parallel-size 1 \\\n",
    "        --host 0.0.0.0 \\\n",
    "        --port 4000 \\\n",
    "        --num-scheduler-steps 10 \\\n",
    "        --max-num-seqs 128 \\\n",
    "        --max-num-batched-tokens 2048 \\\n",
    "        --max-model-len 2048 \\\n",
    "        --distributed-executor-backend \"mp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c2988d-b7b6-487e-9f56-3492b721fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VLLM_USE_TRITON_FLASH_ATTN=0 \\\n",
    "vllm serve Qwen/Qwen3-30B-A3B \\\n",
    "    --served-model-name Qwen3-30B-A3B \\\n",
    "    --api-key abc-123 \\\n",
    "    --port 8000 \\\n",
    "    --enable-auto-tool-choice \\\n",
    "    --tool-call-parser hermes \\\n",
    "    --trust-remote-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2637cc0-3458-4e8d-a22d-aa2458ce8577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-41daa9a3d36847cd95eaf85f5cd4377c', 'object': 'chat.completion', 'created': 1752919883, 'model': 'Qwen/Qwen3-4B', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'reasoning_content': None, 'content': \"<think>\\nOkay, the user is asking me to explain the concept of an AI agent. Let me start by recalling what an AI agent is. From what I know, an AI agent is a system that can perceive its environment and take actions to maximize its chances of achieving a goal. But I need to make sure I'm accurate here.\\n\\nFirst, I should define what an AI agent is. It's an entity that can perform tasks autonomously, using some form of intelligence. The key here is autonomy, as opposed to a simple program that follows a set of instructions. So, the agent interacts with its environment, learns from experiences,\", 'tool_calls': []}, 'logprobs': None, 'finish_reason': 'length', 'stop_reason': None}], 'usage': {'prompt_tokens': 41, 'total_tokens': 169, 'completion_tokens': 128, 'prompt_tokens_details': None}, 'prompt_logprobs': None, 'kv_transfer_params': None}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:4000/v1/chat/completions\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "data = {\n",
    "    \"model\": \"Qwen/Qwen3-4B\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert in the field of AI. Make sure to provide an explanation in few sentences.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the concept of AI Agent.\"\n",
    "        }\n",
    "    ],\n",
    "    \"stream\": False,\n",
    "    \"max_tokens\": 128!\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffdff364-8035-4546-94c5-fd64ad026391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.68 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.69-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting openai<2.0.0,>=1.86.0 (from langchain-openai)\n",
      "  Downloading openai-1.97.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (4.13.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.11.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n",
      "Downloading langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
      "Downloading langchain_core-0.3.69-py3-none-any.whl (441 kB)\n",
      "Downloading openai-1.97.0-py3-none-any.whl (764 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m765.0/765.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai, langchain-core, langchain-openai\n",
      "\u001b[2K  Attempting uninstall: openai\n",
      "\u001b[2K    Found existing installation: openai 1.79.0\n",
      "\u001b[2K    Uninstalling openai-1.79.0:\n",
      "\u001b[2K      Successfully uninstalled openai-1.79.0━━━━\u001b[0m \u001b[32m0/3\u001b[0m [openai]\n",
      "\u001b[2K  Attempting uninstall: langchain-core━━━━━━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [openai]\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.650/3\u001b[0m [openai]\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.65:━━━━━\u001b[0m \u001b[32m0/3\u001b[0m [openai]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.652m0/3\u001b[0m [openai]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [langchain-openai][langchain-openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-core-0.3.69 langchain-openai-0.3.28 openai-1.97.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34672a5b-77f0-4fa7-a7a8-9040f9582cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model=\"Qwen/Qwen3-4B\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=\"...\",  # if you prefer to pass api key in directly instaed of using env vars\n",
    "    base_url=\"http://localhost:4000/v1/\",\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59979e81-12dc-4e89-8eb4-d8bdcc6fb841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user said \"hi\". I need to respond appropriately. Since they just greeted me, I should acknowledge their greeting. Maybe say hello back and offer assistance. Keep it friendly and open-ended. Let them know I\\'m here to help with anything they need. Make sure the response is concise but welcoming. Avoid any technical jargon. Just a simple, warm reply.\\n</think>\\n\\nHello! How can I assist you today? 😊', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 92, 'prompt_tokens': 9, 'total_tokens': 101, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'Qwen/Qwen3-4B', 'system_fingerprint': None, 'id': 'chatcmpl-da753e3773c14c83891bb45f18f41cc5', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--ada57556-d1a1-4a95-be80-c39ff01c1bad-0', usage_metadata={'input_tokens': 9, 'output_tokens': 92, 'total_tokens': 101, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9a04a-cfe6-4184-9ab9-9a3f18291165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
